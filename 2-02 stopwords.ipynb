{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stopwords.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw6M10iZ25L2",
        "colab_type": "text"
      },
      "source": [
        "# stopwords\n",
        "\n",
        "參考資料：\n",
        "\n",
        "* https://www.geeksforgeeks.org/removing-stop-words-nltk-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXprrC8x3R4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeKdMa5O3MGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BondZjmU7JM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boswxnDq3f2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
        "  \n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "word_tokens = word_tokenize(sent) \n",
        "  \n",
        "filtered_sentence = [w for w in word_tokens if (not w.lower() in stop_words) and (not w in string.punctuation)] \n",
        "  \n",
        "print(word_tokens) \n",
        "print(filtered_sentence) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}